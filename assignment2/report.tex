\documentclass[a4wide,12pt]{article}
\usepackage{a4wide}
\usepackage{times}
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{enumerate}
\usepackage{palatino}
\usepackage{rotating}
 
%\usepackage{prooftree}

\usepackage{amsmath, amsthm, amssymb}

\theoremstyle{definition}
\newtheorem{defi}{Definition}
\newtheorem{example}{Example}
\newtheorem*{conj}{Conjecture}
\newtheorem*{prob}{Problem}
\newtheorem*{question}{Question}
\theoremstyle{plain} 
\newtheorem{theo}{Theorem}
\newtheorem{prop}[theo]{Proposition}
\newtheorem{lemma}[theo]{Lemma}
\newtheorem{cor}[theo]{Corollary}
\newtheorem*{theo*}{Theorem}
\newtheorem*{prop*}{Proposition}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{cor*}{Corollary}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notation}{Notation}
\def\qed{\begin{flushright} $\Box$ \end{flushright}}

\newenvironment{prf}
                {\vspace{-2mm} \noindent {\bf Proof.}}
                {\par \nopagebreak \qed }
\newenvironment{namedprf}[1]
                {\noindent {\bf Proof (#1).}}
                {\par \nopagebreak \qed }


\def\logequiv{\Leftrightarrow}

\allowdisplaybreaks[0]
 
\def\eq{\;\; = \;\;}
\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}
 
\def\pset#1{\mathcal{P}(#1)}
\def\A#1{\mathcal{A}[\hspace{-1pt}[#1]\hspace{-1pt}]}
 
\def\const#1{\mathopen{\langle}#1\mathclose{\rangle}} % <a,b,...z>
\def\pair#1{\const{#1}}
 
\def\Stmt {\mathbf{Stmt}}
\def\Lab {\mathbf{Lab}}
\def\Blocks{\mathbf{Blocks}}
\def\Var {\mathbf{Var}}
 
 
\def\skip {\texttt{skip}\ }
\def\whilel{\texttt{while}\ }
\def\dol {\texttt{do}\ }
\def\ifl {\texttt{if}\ }
\def\thenl {\texttt{then}\ }
\def\elsel {\texttt{else}\ }
\def\printl{\texttt{print}\ }
\def\contl {\texttt{continue}\ }
\def\breakl{\texttt{break}\ }
 
\def\haskell{\textsc{Haskell}}
\def\starto{\overset{\star}{\to}}
 
\newcounter{Progenvcount}
\setcounter{Progenvcount}{0}
\newenvironment{progenv}
                {\refstepcounter{Progenvcount} \nopagebreak
                 \bigskip\hrule\nopagebreak\medskip\noindent
                 {\bf Program \arabic{Progenvcount}.} \nopagebreak\vspace{0.3cm} \nopagebreak \\ \nopagebreak
                  \nopagebreak
                 $\begin{array}{ll}}
                {\end{array}$ \bigskip\hrule\bigskip\bigskip }


%\def\programold#1{\fbox{\begin{minipage}{0.5\textwidth}\protect{$\begin{array}{ll} #1 \end{array}$}\end{minipage}}}

\def\restabR#1#2[#3]{
\begin{table}
{\scriptsize
\caption{#1}\label{#3}
\begin{center}\begin{sideways}\input{#2}\end{sideways}\end{center}
}
\end{table}}

\def\restabRtiny#1#2[#3]{
\begin{table}
{\tiny
\caption{#1}\label{#3}
\begin{center}\begin{sideways}\input{#2}\end{sideways}\end{center}
}
\end{table}}


\def\restab#1#2[#3]{
\begin{table}
\caption{#1}\label{#3}
\begin{center}\input{#2}\end{center}
\end{table}}


\def\program#1[#2]{\begin{progenv}\label{#2}\input{#1}\end{progenv}}

\def\Tiny{\fontsize{3pt}{3pt}\selectfont}
\def\hs#1{\texttt{#1}}
 
\begin{document}
\author{Chris Eidhof, Rui S. Barbosa}
\title{Data Flow Assignment II \\ Automatic Program Analysis}
 
\maketitle

\section{~}

Our goal is to prove the correctness of reaching definitions analysis.
We follow the structure of the proof presented in the book for the live
variable analysis.

We start by presenting the analysis itself: the constraints generated for each program. Here,
we make a deviation from the book, dropping the initial undefinedness constraints. For that
modified analysis, we prove results analogous to the propositions 2.16 to 2.21 in the book.
Then, we reintroduce the undefinedness constraints into our analysis and prove the corresponding
correctness result. In the end, we consider the relationship (analogous to Lemma 2.15)
between the analysis using equations and
the corresponding analysis using constraints (which is used for the proof).

\subsection*{The Analysis}

As we said, from here onwards we will consider $\iota$ to be the empty set. In our final result, we
will show how our solution can be adapted for a non-empty $\iota$ that introduces
undefinedness in the beginning.

Thus, the set $RD^\subseteq(S)$ of constraints generated for a program $S$ is:

\begin{align*} 
\label{def_constr}
RD^{\subseteq}(S) = & \; \{RD_{exit}(\ell) \supseteq RD_{entry}(\ell) \setminus kill_{RD}(B^l)) \cup gen_{RD}(B^l) \mid B^l \in blocks(S)\} \\
\cup & \; \{RD_{entry}(\ell) \supseteq RD_{exit}(\ell') \mid (\ell', \ell) \in flow(S) \}
\end{align*}

A solution, $reach$, to the constraint system $RD^\subseteq(S)$ is a pair of functions
\[reach_{entry}, reach_{exit} : \Lab_\star \to \pset{\Var_\star \times (\Lab_\star \cup \{?\})}\] 
that satisfies the constraints (when instantiating $RD_{entry}$/$RD_{exit}$ with $reach_{entry}$/$reach_{exit}$).
In that case, we write
\[reach \models RD^{\subseteq}(S)\]

In what follows, $N$ will stand for $reach_{entry}$ and $X$ for $reach_{exit}$. 


Note that we presented only a constraint system (as opposed to an equation system 
as in the analysis formulation). Actually, just as for the case of live variables analysis,
the correctness proof is much simpler to conduct using constraints.
Nevertheless, the correctness for $RD^\subseteq$ implies the correctness for the corresponding
equation based system. We defer the proof of a result similar to that of Lemma 2.15 in the book
until the end of this section, after we have reintroduced the undefinedness constraints.


\subsection*{Lemmas about the Analysis (cf. 2.16,2.18)}

We present two lemmas about a solution $reach$ to the constraints, which are variants
of lemmas 2.16 and 2.18 in the book for reaching definitions analysis.

The former 
shows that a solution for the constraints of a program is also a solution for the constraints of any
subprogram, that is, in a certain sense, constraints are composed incrementally.
This result will be essential to prove the main theorem, particularly the cases when
the semantic rules have non-empty premisses. 
It is worth noticing that this property would not hold if we took $\iota \neq \emptyset$.

\begin{lemma}[Subprogram Solutions (cf Lemma 2.16)]
\label{lemmasubp}
If $reach \models RD^\subseteq(S_1)$ (with $S_1$ being label consistent) and
$flow(S_1) \supseteq flow(S_2)$ and $blocks(S_1) \supseteq blocks(S_2)$ then
$reach \models RD^\subseteq(S_2)$ (with $S_2$ being label consistent).
\end{lemma}
\begin{proof}
As $S_2$'s flow graph is a subset of $S_1$'s, it is clear from the definition
of the analysis 
that $RD^{\subseteq}(S_2) \subseteq RD^{\subseteq}(S_1)$. Thus, if 
$reach$ solves all the constraints in $RD^\subseteq(S_1)$, then in particular it
solves all that are in $RD^\subseteq(S_2)$ (that is, $reach \models RD^\subseteq(S_2)$).
\end{proof}


The second result simply states that the analysis results are
propagated (forwardly) through the flow graph of the program.

\begin{lemma}[Flow Propagates Results(cf. Lemma 2.18)]
\label{lem218}
If $reach \models RD^\subseteq(S)$ (for $S$ being label consistent) then for all
$(\ell, \ell') \in flow(S)$ we have $reach_{entry}(\ell') \supseteq reach_{exit}(\ell)$.
\end{lemma}
\begin{proof}
Because of the definition of $RD^\subseteq$, this follows
immediately.
\end{proof}

\subsection*{Lemmas about the correctness relation (cf. 2.20) }

We shall now consider some properties about the correctness relation.


The correctness relation, $\sim: (Var \times \Lab)^\star \to \pset{Var_\star \times \Lab_\star}$,
relates traces of programs with analysis results at a certain point. It is defined as
\[tr \sim Y \equiv \forall x \in DOM(tr) \,.\; (x,SRD(tr)(x)) \in Y\]
where $DOM$ and $SRD$ are defined in the book, respectively yielding
the domain of a trace and the label corresponding to the rightmost (most recent) 
occurrence of a certain variable in a trace.

The next lemma is a simple property of the correctness relation. It can be read as a monotonicity property
of $(tr \sim)$ seen as a function to the booleans: if we have a
correct result $Y$ at a certain point, then any ``larger'' result
will still be correct (although less optimal). 

\begin{lemma}[Monotonicity of $(tr \sim)$]
\label{lemmasq}
If $tr \sim Y$ and $Y \subseteq Y'$ then $tr \sim Y'$.
\end{lemma}
\begin{proof}
$tr \sim Y$ means that for all $x \in DOM (tr)$ we have $(x,SRD(tr)(x)) \in Y$. 
As $Y \subseteq Y'$, we also have $(x,SRD(tr)(x)) \in Y'$. Hence, $tr \sim Y'$.
\end{proof}

The following result corresponds to Lemma 2.20 in the book. 
It is similar to Lemma \ref{lem218} in the sense that it concerns what is propagated
through the edges of the flow graph: in this case, the correctness of the analysis results.

\begin{lemma}[Flow Preserves Correctness(cf. Lemma 2.20)]\label{lemmaflow}
Assume $reach \models RD^\subseteq(S)$ with $S$ being label consistent. Then,
$tr \sim X(\ell)$ implies $tr \sim N(\ell')$ for all $(\ell, \ell')$ in $flow(S)$.
\end{lemma}
\begin{proof}
By Lemma \ref{lem218}, we know that $X(\ell) \subseteq N(\ell')$. We then apply Lemma \ref{lemmasq}.
\end{proof}


\subsection*{Correctness Result for $RD^\subseteq$ (cf. 2.21,2.22)}

This is the main step for proving the correctness
of the reaching definitions analysis, similar to Theorem 2.21 in the book.
The theorem below states that the correctness
relation is kept by each single execution step
determined by the semantics.

\begin{theo}[Stepwise Correctness (cf. Theorem 2.21)]
\label{theo221}
Let $S$ be a label consistent program and $reach \models RD^{\subseteq}(S)$. Then:
\begin{enumerate}
\item If $\pair{S,\sigma, tr} \to \pair{S', \sigma', tr'}$ and $tr \sim N(init(S))$, then $tr' \sim N(init(S'))$
\item If $\pair{S,\sigma, tr} \to \pair{\sigma', tr'}$ and $tr \sim N(init(S))$, then $tr' \sim X(init(S))$
\end{enumerate}
\end{theo}
\begin{proof}
The proof of this theorem goes by induction on the tree used to establish
the transition (i.e. computation step) according to the rules of the instrumented operational semantics.

~\\
Case $[ass]$:

We have $\pair{[x := a]^\ell, \sigma, tr} \to \pair{\sigma[x\mapsto\A{a}\sigma], tr:(x,\ell)}$
and $tr \sim N(\ell)$. 


From the constraints,

\begin{equation}\label{assconst}
X(\ell) \supseteq (N(\ell) \setminus \{(x,\ell') \mid \ell' \in \Lab_\star^?\}) \cup \{(x,\ell)\}
\end{equation}

Our goal is to prove that $tr' \sim X(init(S))$, that is to say $(tr:(x,\ell)) \sim X(\ell)$.
Looking at the definition of $\sim$,
this amounts to prove that $(y,SRD(tr')(y)) \in X(\ell)$ for every $y \in DOM(tr')$.

The case for $y=x$ is straightforward as
we then have \[(y,SRD(tr')(y)) = (x,SRD(tr:(x,\ell))(x)) = (x,\ell)\] which can easily be seen to be in $X(\ell)$ from equation \ref{assconst}.

As for $y\neq x$, we have \[(y,SRD(tr')(y)) = (y,SRD(tr:(x,\ell))(y)) = (y,SRD(tr)(y))\] which clearly is in $N(\ell)$ (because $y \in DOM(tr)$ and $tr \sim N(\ell)$).
As $y\neq x$, then it is also in $N(\ell) \setminus \{(x,\ell') \mid \ell' \in \Lab_\star^?\}$, which in turn is contained in $X(\ell)$, by equation \ref{assconst}.

~\\
Case $[skip]$:

We have $\pair{[\skip]^\ell, \sigma, tr} \to \pair{\sigma, tr}$
and $tr \sim N(\ell)$. 
From the constraints we have
\[X(\ell) \supseteq (N(\ell) \setminus \emptyset) \cup \emptyset = N(\ell)\]
Hence, by Lemma \ref{lemmasq}, $tr \sim X(\ell)$.

~\\
Case $[seq1]$:

We have $\pair{S_1;S_2,\sigma,tr} \to \pair{S'_1;S_2,\sigma',tr'}$ and $tr \sim N(init(S_1;S_2))$.
For the rule to apply, we also have $\pair{S_1,\sigma,tr} \to \pair{S'_1,\sigma',tr'}$.
As $S_1$ is a subprogram of $S_1;S_2$, by Lemma \ref{lemmasubp},
we can say that $reach \models RD^{\subseteq}(S_1)$. Also, $init(S_1;S_2) = init(S_1)$, so we have
$tr \sim N(init(S_1))$ and we can then apply the induction hypothesis, giving $tr' \sim  N(init(S'_1))$.
As $init(S'_1) = init(S'_1;S_2)$, we conclude $tr' \sim N(init(S'_1;S_2))$ as required.

~\\
Case $[seq2]$:

We have $\pair{S_1;S_2,\sigma,tr} \to \pair{S_2,\sigma',tr'}$ and $tr \sim N(init(S_1;S_2))$.
The antecedent of the rule is $\pair{S_1,\sigma,tr} \to \pair{\sigma',tr'}$.
For the same reason as in the previous case we can apply the induction hypothesis, obtaining
$tr' \sim X(init(S_1))$. By definition of flow, \[\forall \ell . \; \ell \in final(S_1). \;(\ell,init(S_2)) \in flow(S_1;S_2)\]
By Lemma 2.14 from the book, $final(S_1) = \{init(S_1)\}$ (because the computation ended in one step). Thus,
$(init(S_1),init(S_2)) \in flow(S)$ and Lemma \ref{lemmaflow} gives $tr \sim N(init(S_2))$.

~\\
Case $[if1]$:

We have $\pair{\ifl [b]^\ell\; \thenl S_1\; \elsel S_2,\sigma,tr} \to \pair{S_1,\sigma,tr}$ and $tr \sim N(\ell)$.
From the constraints in $RD^{\subseteq}$, 
\[ X(\ell) \supseteq (N(\ell) \setminus \emptyset) \cup \emptyset = N(\ell)\]
Thus, by \ref{lemmasq}, $tr \sim X(\ell)$. Now, since $(\ell,init(S_1)) \in flow(S)$, we can use Lemma \ref{lemmaflow}
to conclude $tr \sim N(init(S_1))$.

~\\
Case $[if2]$:

The proof is the same as in the previous case, substituting $S_2$ for $S_1$.

~\\
Case $[wh1]$:

We have $\pair{\whilel [b]^\ell \dol S_b,\sigma,tr} \to \pair{S_b;\whilel [b]^\ell \dol S_b,\sigma,tr}$ and $tr \sim N(\ell)$.
Again, from the constraints, we have
\[X(\ell) \supseteq (N(\ell) \setminus \emptyset) \cup \emptyset = N(\ell)\]
As before, $(\ell,init(S_b)) \in flow(S)$. Hence, as in the previous case, Lemmas \ref{lemmasq} and \ref{lemmaflow} give
$tr \sim X(\ell)$ and then
$tr \sim N(init(S_b))$.

~\\
Case $[wh2]$:

We have $\pair{\whilel [b]^\ell \dol S_b,\sigma,tr} \to \pair{\sigma,tr}$ and $tr \sim N(\ell)$.
The constraints give
\[X(\ell) \supseteq (N(\ell) \setminus \emptyset) \cup \emptyset = N(\ell)\]
Thus, by Lemma \ref{lemmasq}, $tr \sim X(\ell)$.

\end{proof}


The previous result can then be lifted to executions consisting of several steps
($\starto$ instead of just $\to$).

\begin{cor}[Execution Correctness (cf. Corollary 2.22)]\label{cor222}
If $reach \models RD^\subseteq(S)$ (with $S$ being label consistent) then:


\begin{enumerate}
\item If $\pair{S, \sigma, tr} \starto \pair{S', \sigma', tr'}$ and $ tr \sim
N(init(S))$ then $tr' \sim N(init(S'))$
\item If $\pair{S, \sigma, tr} \starto \pair{\sigma', tr'}$ and $ tr \sim
N(init(S))$ then $tr' \sim X(\ell)$ for some $\ell \in final(S)$.
\end{enumerate}
\end{cor}
\begin{proof}
This proof is by mathematical induction on the length of the derivation sequence and uses
Theorem \ref{theo221} at each step.
\end{proof}


\subsection*{Introducing Undefinedness (?s)}

Informally, the above result means that execution of a piece of code keeps the analysis results correct with respect to the semantics.
That is, if we have $reach \models RD^\subseteq(S)$ and we have a correct analysis result for $reach_{entry}(init(S))$, then the analysis results will
be correct with respect to every possible path at all (reachable) program points. 
This is exactly what one would expect from a solution to $RD^\subseteq(S)$. 

We now consider the whole $RD$ analysis:
for a program $S_\star$, we generate all the constraints in $RD^\subseteq(S_\star)$ plus a constraint
introducing variable undefinedness at the beginning. 
 
\[RD^\subseteq_\star(S_\star) = RD^\subseteq(S_\star) \cup \{ \{(x,?) \mid x \in
\Var_\star\} \subseteq RD_{entry}(init(S_\star)) \}\]

This set of constraints is intended to be applied only once, for the ``full'' program.
The idea is that it correctly captures the semantics of executions of complete programs
(but not of subprograms where some code has already been executed, unless we want to ``forget''
that code).
The idea is that the old constraints guarantee the results are correctly propagated to each (reachable)
program point (as seen in Corollary \ref{cor222}) while the new constraint give us correct results to start with.

In fact, on the semantics side, a full evaluation of $S_\star$ starts from $\pair{S_\star,\sigma,tr_0}$
where $\sigma$ is some initial state and $tr_0$ is the trace at the beginning, where yet no code
has been executed:
\[tr_0 = [ (x,?) \mid x \in Var_\star(S_\star) ] \]

With these definitions, we can then formulate our correctness result.
\begin{theo}[Correctness of $RD^\subseteq_\star$]
If $reach \models RD_\star^\subseteq(S_\star)$ (with $S_\star$ being label consistent) then:

\begin{enumerate}
\item If $\pair{S_\star, \sigma, tr_0} \starto \pair{S', \sigma', tr'}$ then $ tr' \sim
N(init(S'))$ 
\item If $\pair{S_\star, \sigma, tr_0} \starto \pair{\sigma', tr'}$ then $ tr' \sim
X(\ell)$ for some $\ell \in final(S_\star)$.
\end{enumerate}
\end{theo}
\begin{proof}
Let $reach \models RD_\star^\subseteq(S_\star)$. Then, in particular,
$\{(x,?) \mid x \in \Var_\star\} \subseteq N(init(S_\star))$  is satisfied. So
$tr_0 \sim N(init(S_\star))$. Also,
$reach \models RD^\subseteq(S_\star)$, thus Corollary \ref{cor222} holds. Applying it
to $\pair{S_\star,\sigma,tr_0}$, knowing that $tr_0 \sim N(init(S_\star))$,
we get the desired result.
\end{proof}

 
\subsection*{Equation-Based Analysis (cf. Lemma 2.15)}

We now consider the relationship between the constraint-based system considered so far and 
the correspondent equation based system $RD^=_\star$, where all inclusions are replaced by equalities.
The following result is analogous to Lemma 2.15 in the book and holds whether we consider undefinedness
($RD^{\subseteq/=}_\star$) or not ($RD^{\subseteq/=}$). 


\begin{lemma}[Relationship between $RD_\star^\subseteq$ and $RD_\star^=$ (cf. Lemma 2.15)]
Consider a label consistent program $S_\star$.  If $reach \models RD_\star^=(S_\star)$
then $reach \models RD_\star^\subseteq(S_\star)$. The least solution of $RD_\star^=(S_\star)$ coincides
with the least solution of $RD_\star^\subseteq$.
\end{lemma}
\begin{proof}
If $reach \models RD_\star^=(S_\star)$
then clearly $reach \models RD^\subseteq_\star(S_\star)$ because $=$ is a subrelation of $\supseteq$
(equality is a particular case of inclusion).

Next we prove that $reach \models RD_\star^\subseteq(S_\star)$ has the same least solution
as  $reach \models RD_\star^=(S_\star)$.
The proof is the same as in the book, using Tarski's Fix Point Theorem.
So, we just need to guarantee that it can be applied, that is, that 
function $F_{RD_\star}^{S_\star}$ (as defined in chapter 1 of the book) is a monotone
function in a complete lattice.
Note that function $F_{RD_\star}^{S_\star}$
has type $\vec{L} \to \vec{L}$ where $\vec{L}$ is a direct product
of power sets: $(\pset{\Var_\star \times \Lab_\star})^{2|\Lab_\star|}$. Thus, it is a complete lattice. 
To see that it is monotone
we  notice that the right hand side of each component of $F_{RD_\star}^{S_\star}$
is composed by operation that preserve monotonicity: set union and subtraction
by constant sets.
Thus, given a tuple with pointwise
larger sets, we also get larger sets in the resulting tuple.
\end{proof}


\section{~} 
%PART 2

\subsection{Analysis}

For our data flow equations, we reuse the general definition 
described in section 2.5.3 of the book and we just change the analysis specific parts of it.

We extend our lattice to take the context into account
\begin{align*}
\widehat{L} & = \Delta \to L = \Delta \to \pset{\Var_\star}
\end{align*}

Then, the data flow equations will read as below.
\begin{align*}
LV_{entry}(\ell) & = \widehat{f_\ell}(LV_{exit}(\ell)) \text{for labels not in \texttt{call}}\\
LV_{exit}(\ell) &= \bigsqcup{LV_{exit}(\ell') \mid (\ell,\ell') \in flow(S_\star) \lor (\ell;\ell') \in flow(S_\star)}\\
LV_{entry}(\ell_r) &= \widehat{f^1_{\ell_c}}(LV_{exit}(\ell_r)) \text{\;for all $(l_c,l_n,l_x,l_r) \in interflow(S_\star)$}\\
LV_{entry}(\ell_c) &= \widehat{f^2_{\ell_r,\ell_c}}(LV_{exit}(\ell_r),LV_{exit}(\ell_c)) \text{\;for all $(l_c,l_n,l_x,l_r) \in interflow(S_\star)$}\\
\end{align*}

We now need to instantiate the transfer functions $\widehat{f_\ell} : \hat{L} \to \hat{L}$.

Just like in the book, we lift the regular transfer function $f_\ell$ to $\widehat{f_\ell}$ at the points
where it is defined.
\begin{align*}
\widehat{f_l} & : \widehat{L} \to \widehat {L} \\
\widehat{f_l} (\widehat{l}) & = f_l \circ \widehat{l}
\end{align*}

Now we still need to give the cases for \texttt{proc} and \texttt{call}. For
a procedure
\texttt{proc p (val x, res y) is$^{\ell_n}$ S end$^{\ell_x}$}
we give two transfer functions (at the beginning and end of the procedure).
Both $f_{\ell_n}$ and $f_{\ell_x}$ are the identity function.

Thus all the hard work is
done in the procedure calls.
Given $(\ell_c, \ell_n, \ell_x, \ell_r) \in IF$, we have the following call and the corresponding
procedure:
\begin{align*}
& \texttt{[call p (a, z)]$^{\ell_c}_{\ell_r}$} \\
& \texttt{proc p (val x, res y) is$^{\ell_n}$ S end$^{\ell_x}$}
\end{align*}
Closely following the book, we now define $f^1_{\ell_r}$ and $f^2_{\ell_r,\ell_c}$ (note that
this is a backward analysis) which are the transfer functions not yet taking the context into account.  
The intuition for our $f^1_{\ell_r}$ function is that at the end of a procedure we are going
to have the same live variables that are live after the call except for the parameters and we only make the result
live if it is actually used (live) after the call. Before the call we get $w$ (which is the set of live variable 
in the beginning of the procedure) and we will
take out the parameters again, make sure we add every free variable in the
argument for the call and add $x$ and $y$ only if they are in $v$, that is, they are live after the call
(we have to compensate for the shadowing in the procedure).
 
\begin{align}
f^1_{\ell_r} (v) & = (v \setminus \{x, z\}) \cup \{y \mid z \in v\} \\
f^2_{\ell_r, \ell_c} (v, w) & = (w \setminus \{x, y\}) \cup FV(a) \cup (v \cap \{x, y\} \setminus \{z\})
\end{align}

Now we are ready to give the context-sensitive functions for call strings with
unbounded length.

\begin{align}
\widehat{f^1_{\ell_r}} (\widehat{\ell}) (\delta) & = \bigsqcup \{ f^1_{\ell_r} (\widehat{\ell}(\delta') \mid \delta = \ell_r : \delta' \} \\
\widehat{f^2_{\ell_r, \ell_c}} (\widehat{\ell'}, \widehat{\ell}) (\delta) & = f^2_{\ell_r, \ell_c} (\widehat{\ell'}(\delta), \widehat{\ell}(\ell_r : \delta))
\end{align}

When doing call strings of bounded length $k$, we replace our $cons$-operator by
$:_k$ which is defined as following:

\begin{align}
x :_k xs = take\ k\ (x : xs)
\end{align}

Now we can use our previous definitions with $:$ replaced by $:_k$:

\begin{align}
\widehat{f^1_{\ell_r}} (\widehat{\ell}) (\delta) & = \bigsqcup \{ f^1_{\ell_r} (\widehat{\ell}(\delta') \mid \delta = \ell_r :_k \delta' \} \\
\widehat{f^2_{\ell_r, \ell_c}} (\widehat{\ell'}, \widehat{\ell}) (\delta) & = f^2_{\ell_r, \ell_c} (\widehat{\ell'}(\delta), \widehat{\ell}(\ell_r :_k \delta))
\end{align}

\subsection*{Example}

We now present two small programs that shows how the transfer functions work with
and without shadowing.

\begin{progenv}
\texttt{begin} \\
\;\;\texttt{proc $id$ (val $x$, res $y$) is} ^{1}\\
\;\;\;\;\lbrack y := x\rbrack^{2};\\
\;\;\texttt{end}^3 \\
\;\;\lbrack \texttt{call } id\;(x + 1, y)\rbrack^{4}_{5};\\
\;\;\lbrack r := x + y\rbrack^{6};\\
\texttt{end}
\end{progenv}

Two notable equations for Program 1 are:

\begin{align*}
f^1_{5} (v) & = (v \setminus \{x, y\}) \cup \{y \mid y \in v\} \\
f^2_{5, 4} (v, w) & = (w \setminus \{x, y\}) \cup \{x\} \cup (v \cap \{x, y\} \setminus \{y\})
\end{align*}

Clearly, $X(5) = N(6) = \{x, y\}$. Then 
\begin{align*}
N(5)  & = f^1_5(X(5))  \\
      & = f^1_5(\{x,y\})  \\
      & = (\{x, y\} \setminus \{x, y\}) \cup \{y \mid y \in \{x, y\}\}  \\
      & = \{y\} 
\end{align*}
Moreover, at the beginning of the procedure we will have $X(4) = N(1) = \{x\}$.
And then 
\begin{align*}
N(4) & = f^2_{5, 4} (X(5), X(4))  \\
     & = f^2_{5, 4} (\{x, y\}, \{x\}) \\
     & = (\{x\} \setminus \{x, y\}) \cup \{x\} \cup (\{x, y\} \cap \{x, y\} \setminus \{y\}) \\
     & = \emptyset \cup \{x\} \cup \{x\} \\
     & = \{x\}
\end{align*}

\begin{progenv}
\texttt{begin} \\
\;\;\texttt{proc $id$ (val $x$, res $y$) is} ^{1}\\
\;\;\;\;\lbrack y := x\rbrack^{2};\\
\;\;\texttt{end}^3 \\
\;\;\lbrack \texttt{call } id\;(t, z)\rbrack^{4}_{5};\\
\;\;\lbrack r := z + q\rbrack^{6};\\
\texttt{end}
\end{progenv}

Now for Program 2 we have

\begin{align*}
f^1_{5} (v) & = (v \setminus \{x, z\}) \cup \{y \mid z \in v\} \\
f^2_{5, 4} (v, w) & = (w \setminus \{x, y\}) \cup \{t\} \cup (v \cap \{x, y\} \setminus \{z\})
\end{align*}

Clearly, $X(5) = N(6) = \{z, q\}$. Then 
\begin{align*}
N(5)  & = f^1_5(X(5))  \\
      & = f^1_5(\{z,q\})  \\
      & = (\{z, q\} \setminus \{x, z\}) \cup \{y \mid z \in \{z, q\} \\
      & = \{y, q\} 
\end{align*}
Moreover, at the beginning of the procedure we will have $X(4) = N(1) = \{x, q\}$.
And then 
\begin{align*}
N(4) & = f^2_{5, 4} (X(5), X(4))  \\
     & = f^2_{5, 4} (\{z, q\}, \{x, q\}) \\
     & = (\{x, q\} \setminus \{x, y\}) \cup \{t\} \cup (\{z, q\} \cap \{x, y\} \setminus \{z\}) \\
     & = \{q\} \cup \{t\} \cup \emptyset \\
     & = \{q, t\}
\end{align*}

\subsection*{Result Example}

As an example, we worked out the analysis for the \texttt{fib} program presented in the book.

We have labelled the program starting with the main body, then
the procedure \texttt{fib} and finally the procedure \texttt{add}.

We only give the $X$-value for the interesting cases (label 1 and 14), where it differs
from the $N$-value. Basically, these are the edges where there are assignments to variables
that become live, thus the edges where the analysis results really changes).

\begin{table}
$
\begin{array}{lcccccccccccccccccccccccccccccccccccc}
\  & [11, 11] & [9, 11] & [7, 11] & [3] & [11, 3] & [9, 3] & [7, 3] & [11, 9] & [9, 9] & [7, 9] & [\,] \\
N(1)  & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \{x\}     \\
X(1)  & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \{x, y\}  \\
N(2)  & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \{x, y\} \\
N(3)  & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset \\
N(4)  & \{ z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \emptyset & \emptyset \\
N(5)  & \{ z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \emptyset & \emptyset \\ 
N(6)  & \{    y\}   & \{   y\}   & \emptyset & \{   y\}   & \{   y\}   & \{   y\}   & \emptyset & \{   y\}   & \{y   \}   & \emptyset & \emptyset \\
N(7)  & \{    y\}   & \{   y\}   & \emptyset & \emptyset & \emptyset &    y   & \emptyset &    y   & y      & \emptyset & \emptyset \\
N(8)  & \{ z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \emptyset & \emptyset \\
N(9)  & \{ z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \emptyset & \emptyset \\
N(10) & \{ z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \{z, y\}   & \emptyset & \{z, y\}   & \{z, y\}   & \emptyset & \emptyset \\
N(11) & \{    y\}   & \{   y\}   & \emptyset & \emptyset & \emptyset &    \{y\}   & \emptyset &    \{y\}   & \{y\}      & \emptyset & \emptyset \\
N(12) & \{    y\}   & \{   y\}   & \emptyset & \emptyset & \emptyset &    \{y\}   & \emptyset &    \{y\}   & \{y\}      & \emptyset & \emptyset \\
N(13) & \emptyset & \emptyset & \{y, u\}   & \emptyset & \emptyset & \emptyset & \{y, u\}   & \emptyset & \emptyset & \{y, u\}   & \emptyset \\
N(14) & \emptyset & \emptyset & \{y, u\}   & \emptyset & \emptyset & \emptyset & \{y, u\}   & \emptyset & \emptyset & \{y, u\}   & \emptyset \\
X(14) & \emptyset & \emptyset & \{y   \}  & \emptyset & \emptyset & \emptyset & \{y\}     & \emptyset & \emptyset & \{y\}     & \emptyset \\
N(15) & \emptyset & \emptyset & \{y   \}   & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \{y\}      & \emptyset \\
N(16) & \emptyset & \emptyset & \{y   \}   & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \emptyset & \{y\}      & \emptyset
\end{array}
$
\end{table}

\end{document}  

