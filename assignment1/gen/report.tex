\documentclass[a4wide,12pt]{article}
\usepackage{a4wide}
\usepackage{times}
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{enumerate}
\usepackage{palatino}
\usepackage{rotating}
 
\usepackage{prooftree}

%include lhs2tex.fmt 
 
\usepackage{amsmath,amsthm,amssymb}
\allowdisplaybreaks[0]
 
\def\eq{\;\; = \;\;}
\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}
 
\def\pset#1{\mathcal{P}(#1)}
\def\A#1{\mathcal{A}[\hspace{-1pt}[#1]\hspace{-1pt}])}
 
\def\const#1{\mathopen{\langle}#1\mathclose{\rangle}} % <a,b,...z>
\def\pair#1{\const{#1}}
 
\def\Stmt {\mathbf{Stmt}}
\def\Lab {\mathbf{Lab}}
\def\Blocks{\mathbf{Blocks}}
\def\Var {\mathbf{Var}}
 
 
\def\skip {\texttt{skip}\ }
\def\while{\texttt{while}\ }
\def\do {\texttt{do}\ }
\def\ifl {\texttt{if}\ }
\def\thenl {\texttt{then}\ }
\def\elsel {\texttt{else}\ }
\def\print{\texttt{print}\ }
\def\cont {\texttt{continue}\ }
\def\breakc{\texttt{break}\ }
 
\def\haskell{\textsc{Haskell}}
 
\newcounter{Progenvcount}
\setcounter{Progenvcount}{0}
\newenvironment{progenv}
                {\refstepcounter{Progenvcount} \nopagebreak
                 \bigskip\hrule\nopagebreak\medskip\noindent
                 {\bf Program \arabic{Progenvcount}.} \nopagebreak\vspace{0.3cm} \nopagebreak \\ \nopagebreak
                  \nopagebreak
                 $\begin{array}{ll}}
                {\end{array}$ \bigskip\hrule\bigskip\bigskip }


%\def\programold#1{\fbox{\begin{minipage}{0.5\textwidth}\protect{$\begin{array}{ll} #1 \end{array}$}\end{minipage}}}

\def\restabR#1#2[#3]{
\begin{table}
{\scriptsize
\caption{#1}\label{#3}
\begin{center}\begin{sideways}\input{#2}\end{sideways}\end{center}
}
\end{table}}

\def\restabRtiny#1#2[#3]{
\begin{table}
{\tiny
\caption{#1}\label{#3}
\begin{center}\begin{sideways}\input{#2}\end{sideways}\end{center}
}
\end{table}}


\def\restab#1#2[#3]{
\begin{table}
\caption{#1}\label{#3}
\begin{center}\input{#2}\end{center}
\end{table}}


\def\program#1[#2]{\begin{progenv}\label{#2}\input{#1}\end{progenv}}

\def\Tiny{\fontsize{3pt}{3pt}\selectfont}
\def\hs#1{\texttt{#1}}


 
\begin{document}
\author{Chris Eidhof, Rui S. Barbosa}
\title{Data Flow Assignment I \\ Automatic Program Analysis}
 
\maketitle

\section{~}
 
Our analysis for Strongly Live Variables is almost the same as the Live
Variables analysis. We now only present the changes made.

Below is the definition of the $gen_{SLV}$ and $kill_{SLV}$ functions.
Note that we changed the $gen$ function to take an
extra argument $l$ of type $L = \pset{\Var_\star}$ which
corresponds to the set of strongly live variables at the exit of the corresponding block.
This is needed because the strong liveliness of a variable before
being used in an assignment block
depends on whether the assigned variable is strongly live at the exit of that block.
 
\begin{align*}
kill_{SLV} & \; : \; \Blocks_\star \to \pset{\Var_\star} \\
kill_{SLV}([x:=a]^\ell) & \eq \{x\} \\
kill_{SLV}([\skip]^\ell) & \eq \emptyset\\
kill_{SLV}([b]^\ell) & \eq \emptyset \\
\\
gen_{SLV} & \; : \; \Blocks_\star \times \pset{\Var_\star} \to \pset{\Var_\star} \\
gen_{SLV}([x:=a]^\ell,l) & \eq
         \begin{cases}
          FV(a) & \text{if $x \in l$} \\
          \emptyset & \text{otherwise}
         \end{cases} \\
gen_{SLV}([\skip]^\ell,l) & \eq \emptyset\\
gen_{SLV}([b]^\ell,l) & \eq FV(b)
\end{align*}
 
This means our $f_\ell$ also has to change too:
 
\[ f_\ell(l) \eq (l \setminus kill([B]^\ell)) \cup gen([B]^\ell, l) \;\; \text{where} \;\; [B]^\ell
\in blocks(S_\star)
\]
 
Moreover, in our analysis, $\iota$ will not be necessarily empty. Instead, it will be a chosen set of
variables of interest.
By now, there are no means for a program
to communicate its results besides the inspection of some variables when execution halts: those variables
are what we call the variables of interest at the end of the program. Clearly,
those variables need to be considered live at the exit of all final blocks, so that we can always inspect their values.
When $\iota$ is empty, the only way to have intermediate
non-empty sets of strongly live variables will be by using them in conditional expressions (which control the
flow of the program). In that case, we are not interested in any output from the program.
As we shall see, the print statement
to be introduced later will change this situation, as it will allow for
a program to communicate to the outside at any point of execution. 
 
\section{~}
 
We developed some modules in \haskell\ which allow us to define and perform
data flow analysis on \textsc{While} programs. To define an analysis,
one needs to specify how to create a monotone framework from a program.
For the flow graph generation, one can use the functions \hs{forward} and \hs{backward}.
As for the transfer functions, also a few useful combinators were introduced, mainly
for the cases when the underlying lattice is a set: \hs{may} and \hs{must}
can be used to specify which operation to use and there is also special support
for the common $gen/kill$ transfer functions (\hs{genkill}) and for
$gen/kill$ functions that can receive an additional parameter as in the case of SLV
(\hs{depgenkill}). Having defined the conversion from programs to monotone frameworks,
our modules automaticaly generate the equations, solve them through chaotic iteration
and group the results in a table written to \TeX\ format. 

As an example, the definition of SLV will read as:

{\small
\begin{verbatim}
stronglivevariables i  =
       createDataFlowAnalyser
         backward
         (may (const i,const( depgenkill(genSLV,const.killSLV) ) ))
\end{verbatim}
}

\noindent
where the \hs{genSLV} and \hs{killSLV} are just as defined in the previous part. Then, we just define

{\small
\begin{verbatim}
doSLV iota = (resultToTable ("SLV",True,"exit","entry") .
             scan_analyze (stronglivevariables S.empty) . labelProgram)
\end{verbatim}
}

\noindent
which is a function that given a set of variables of interest
and an unlabeled program, performs the strong live variable analysis and displays
the intermediate results in a \TeX\ table.


To demonstrate the Strongly Live Variable Analysis, we will use this \haskell program
to perform chaotic iteration on the following simple example program

\newpage
\program{prog.tex}[prog]

 
Tables \ref{resultr}, \ref{resulty}, \ref{resulta} and \ref{resultempty}
display a trace of the chaotic iteration algorithm for several different values
for $\iota$. The last two columns are always repeated, indicating that the process
has stabilized, reaching a fix point. We have the guarantee that this situation
always happens eventually. For comparison purposes, we have also
used our module to perform (regular) Live Variable Analysis on
the same program, obtaining the results in Table \ref{result_lv}.

 
\restabRtiny{Strongly Live Variable Analysis on Program \ref{prog} with $\iota = \{r\}$}{resultr.tex}[resultr]

\restab{Strongly Live Variable Analysis on Program \ref{prog} with $\iota = \{y\}$}{resulty.tex}[resulty]

\restab{Strongly Live Variable Analysis on Program \ref{prog} with $\iota = \{a\}$}{resulta.tex}[resulta]

\restab{Strongly Live Variable Analysis on Program \ref{prog} with $\iota = \emptyset$}{resultempty.tex}[resultempty]

\restab{Live Variable Analysis on Program \ref{prog}}{result_lv.tex}[result_lv]

We can easily observe that the results of the SLV analysis significantly vary depending on $\iota$. 
If we are interested in knowing the value of $r$ in the end (by the way, that would be the power
function, computing $x^y$), then the result of the analysis is
just that of simple life variable analysis. One can observe that both analysis detect the indirection
through $t$ when decrementing the value of $y$: \emph{between} labels 5 and 6,
both analysis detect that $y$ is dead and $t$ is alive instead. On the opposite side, let us look
more closely to the results for $\iota = \emptyset$. As we have already said, this can be
thought of as if we do not require any response from the program. Being so, one could
safely ignore all the assignments
which are only used to 
produce results and do not interfere (not even indirectly) with the execution flow control.
The only variables that need
to be considered live at a point are those which carry values that will eventually be used
to determine the trace of execution (that will be used in a while or if condition). As we can observe,
the SLV analysis is able to detect that only the variable $y$ (and, between statements $5$ and $6$, 
the variable $t$) will be ever used to determine the flow of the program. Actually, the number of iterations of the while loop that will be done depends only on the value of $y$ at the start of the program
(thus $SLV_{entry}(1) = \{y\}$). The regular live variable analysis is not able to detect this.
For example, the variable $x$ will be live at the entry of the
while loop, because its value will be used to change the value of $r$ in the execution of the body.
However, it is a faint variables in this case, because the value of $r$ will never be used:
when the end of the program is reached, its value is just forgotten without having ever been used
except in assignments to other variables ($a$ and $r$ itself) which are just faint or dead themselves.
The other cases for $\iota$ are similar and we will not discuss them.


\section{~}
 
We start by adding the new labelled constructs to the abstract syntax of the language:
\begin{align*}
 Stmt ::= \; & \ldots \\
 ~ |\;\; & [\print a]^\ell \\
 ~ |\;\; & [x_1,\ldots,x_n := a_1,\ldots,a_n]^\ell , n \in \N \\
 ~ |\;\; & [\cont]^\ell \\
 ~ |\;\; & [\breakc]^\ell
\end{align*}
 
We also extend the $blocks$ function accordingly in a pretty straightforward manner. The definition
of the $labels$ function given in the book stays valid.
\begin{align*}
 blocks([\print a]^\ell) & \eq \{[\print a]^\ell\} \\
 blocks([x_1,\ldots,x_n := a_1,\ldots,a_n]^\ell) & \eq \{[x_1,\ldots,x_n := a_1,\ldots,a_n]^\ell\} \\
 blocks([\cont]^\ell) & \eq \{[\cont]^\ell\} \\
 blocks([\breakc]^\ell) & \eq \{[\breakc]^\ell\}
\end{align*}
 
 
Then, for each of those constructs, we shall give a description of its semantics (the actual rules may be found
in table \ref{semantics}) and explain the modification that need to be done
to the monotone framework, particularly to the functions defining the flow control
($init$, $final$ and $flow$) as well as to the $gen_{SLV}$ and $kill_{SLV}$ functions
which define our analysis. We also give some example
programs in order to demonstrate the resulting analysis.
 
\subsection{Print}
 
Informally, the semantics of this construct will be to write the value of arithmetic expression $a$
to an output stream.
When defining the formal
semantics, we will add an extra component to the state corresponding to the
list of values printed so far ($out \in Z^\star$). The new state will then be
$\sigma = (\eta,out) \in (Var \to \Z) \times \Z^\star$ and the old rules will stay valid
if we interpret $\sigma[x \mapsto y] = (\eta,out)[x \mapsto y]$ as $(\eta[x \mapsto y],out)$.
 

This new construct has no effect on the flow control of the program. Hence, the related functions are
defined just as for the other simple statements (assignments and $\skip$).
\begin{align*}
init([\print a]^\ell) & = \ell \\
final([\print a]^\ell) & = \{\ell\} \\
flow([\print a]^\ell) & = \emptyset
\end{align*}
 
From the Strongly Live Variables Analysis point of view, what is relevant is
the added constraint that all the variables used in expression $a$ need to be
considered (strongly) live when entering the $[\print a]^\ell$ block. Hence, the $gen$ and $kill$ are extended in this way:
\begin{align*}
kill_{SLV}([\print a]^\ell) & \eq \emptyset \\
\\
gen_{SLV}([\print a]^\ell,l) & \eq FV(a)
\end{align*}
 
Note that the $\print$ construct provides the program with a new capability of conveying
results to the outside. Thus, we are not required to consider $\iota \neq \emptyset$ from now on.
We simply need to print the so called variables of interest at the end of our program.
Of course, we can do that anywhere else, thus giving the possibility of inserting
variables of interest at any point.
For example, replacing the $\skip$ by  $[\print r]$ at the end of program \ref{prog}
(obtaining Program \ref{progprtr}),
we get the results in Table \ref{resultr_prt}. Those are (almost) the
same as in Table \ref{resultr}, the only difference being that, after the $\print$ statement,
$r$ is not alive in this case (which is clearly expectable).
 
\program{progprtr.tex}[progprtr]

\restabRtiny{Strongly Live Variable Analysis on Program \ref{progprtr} (print statement) with $\iota = \emptyset$}{resultr_prt.tex}[resultr_prt]
 
\subsection{Simultaneous Assignements}
 
The meaning of multiple assignments ($[v_1,\ldots,v_n := a_1,\ldots,a_n]^\ell$) is
pretty straightforward: all expressions in the right hand side are evaluated and
then each of them is assigned to the corresponding variable on the left hand side, in left to right order.
 
As in the previous case, the flow related functions are easily extended.
\begin{align*}
init ([v_1,\ldots,v_n = a_1,\ldots,a_n]^\ell) & \eq \ell \\
final([v_1,\ldots,v_n = a_1,\ldots,a_n]^\ell) & \eq \{\ell\} \\
flow ([v_1,\ldots,v_n = a_1,\ldots,a_n]^\ell) & \eq \emptyset
\end{align*}
 
Clearly, as with simple assignements, the $kill$
function just enumerates the variables which are assigned to in $\ell$.
 
On the other hand, the
$gen$ function needs to give all the variables required to be strongly live before the block.
As a first guess, we could include all the
free variables used in expressions assigned to variables which are strongly live after the block, closely following the
single assignement case. However, this solution is not optimal in the case where the $v_i$ are not pairwise distinct.
For example, let us consider the block $[x,y,x := a,b,c]^\ell$) and say $x$ and $y$ are
strongly live after it. Then, the variables in expression
$a$ need not be considered strongly live before the block, as the attribution $x:=a$ will be immediately overwritten
by $x:=c$ (recall that attributions are done in left to right order).
 
Therefore, we extend the $kill$ and $gen$ functions in the following manner:
\begin{align*}
kill_{SLV}([v_1,\ldots,v_n := a_1,\ldots,a_n]^\ell) & \eq \{v_i \;|\; 1 \leq i\leq n\} \\
\\
gen_{SLV}([v_1,\ldots,v_n := a_1,\ldots,a_n]^\ell,l) & \eq \bigcup\{FV(a_i) \;|\; v_i \in l \wedge \neg \exists j : j>i \,.\, v_j = v_i\}
\end{align*}
 
To demonstrate the use of this construct, let us again consider a slightly modified version of Program
\ref{progprtr}, where the assignments inside the loop have been grouped togheter. Also, a new (dummy)
assignment was added to illustrate the situation when multiple assignments to the same
variable occur.

\program{progmassr.tex}[progmassr]

Performing Strongly Live Variable Analysis on this program yields
the results on Table \ref{resultr_mass}.
We can easily notice that, although $a$ is used in an expression which is attributed to variable
$y$ (which is strongly live after the assignment), it is not considered
live before that multiple assignment because $y$ appears twice in the assigned variables and the second (rightmost) assignment overrides the one that depends on the value of $a$.

\restabR{Strongly Live Variable Analysis on Program \ref{progmassr}(multiple assignments) with $\iota = \emptyset$}{resultr_mass.tex}[resultr_mass]
 
\subsection{Break and Continue}
The meaning of these constructs inside while loops is just what we are used to:
a $\breakc$ statement cause the program to jump immediately out of the loop whilst
a $\cont$ statement \emph{restarts} the while loop execution (including testing the condition).
If the constructs are found outside of a while loop, the compiler/interpreter should give an error before doing the analysis (it is a simple syntactic check).
 
The formal semantics could be given in a way resembling exception handling in Java (where while loops take
the r\^{o}le of catch), as we briefly explain. These constructs
would cause execution to halt in a new kind of state
enclosing the information of the \emph{then current} state along with an annotation of the reason
for halting ($\breakc$ or $\cont$). 
We would then need several rules to deal with those halting states.
Firstly, we would need to propagate the halting states unchanged through consecutive statements:
sequencing ($;$) with another statement would ignore that second statement and enclosing
if-then-else constructs would also propagate the halting state (for the latter situation, the current
rule suffices). Finally, the way to deal with $\while$ should also change. A possibility
is to change the $[wh_1]$ rule so that it takes a look similar to that of $[seq_1]$.
Then, if the body statement results in a $\cont$-annotated state, the annotation is dropped
and the while loop restarted. If halting state of the body is $\breakc$-annotated,
the annotation is also
dropped but the execution of the while loop would be considered finished.
 
It is worth noticing that if a computation ends in an annotated state and there is
no enclosing while loop, the program itself as a whole would end in that kind of state.
We will consider that to be a error terminating program. Our framework will not consider
the top-level $\breakc$ and $\cont$ statements to be part of the final statements of
a program. That means that we do not care about the values of the variables of interest
if the program terminates in that way. 
This should cause no harm because, as noticed above, a program with top-level
$\breakc$ or $\cont$ statements could be easily ruled out as invalid. 
On the other hand, this assumption will facilitate the definition of
the flow related functions: for example, as we consider that a $\cont$ statement is not
a final statement of $S_1$, then the definition of $flow(S_1;S_2)$ does not consider the flow
from the $\cont$ statement to $init(S_2)$, just like one would expect. We then need to account
for the existence of these constructs in the definition of the flow information functions
for $\while$ statements (as well as the $\breakc$ and $\cont$, of course).
Those definitions now read:
\begin{align*}
init ([\cont]^\ell) &\eq \ell & init ([\breakc]^\ell) &\eq \ell \\
final([\cont]^\ell) &\eq \emptyset & final([\breakc]^\ell) &\eq \emptyset \\
flow ([\cont]^\ell) &\eq \emptyset & flow ([\breakc]^\ell) &\eq \emptyset
\end{align*}
\begin{eqnarray*}
init (\while [b]^\ell \do S) &\eq& \ell \\
final(\while [b]^\ell \do S) &\eq& \ell \cup breaksOf(S) \\
flow (\while [b]^\ell \do S) &\eq& \{(l,init(S))\} \cup flow(S) \\
                            & & \cup\; \{(l',l) | l' \in final(S)\} \\
                            & & \cup\; \{(l',l) | l' \in continuesOf(S)\}
\end{eqnarray*}
where $continuesOf$ and $breaksOf$ functions are auxiliary functions which map a given program statement
to the labels of its top level (not nested in a $\while$) $\cont$ and $\breakc$ statements, respectively.
 
\begin{align*}
continuesOf & \; : \; \Stmt \to \pset{\Lab} \\
continuesOf([x:=a]^\ell) & \eq \emptyset \\
continuesOf([\skip]^\ell) & \eq \emptyset \\
continuesOf([x_1,\ldots,x_:=a_1,\ldots,a_n]^\ell) & \eq \emptyset \\
continuesOf([\print a]^\ell) & \eq \emptyset \\
continuesOf([\cont]^\ell) & \eq \{\ell\} \\
continuesOf([\breakc]^\ell) & \eq \emptyset \\
continuesOf(S_1;S_2) & \eq continuesOf(S_1) \cup continuesOf(S_2) \\
continuesOf(\ifl [b]^\ell \thenl S_1 \elsel S_2) & \eq continuesOf(S_1) \cup continuesOf(S_2) \\
continuesOf(\while [b]^\ell \do S) & \eq \emptyset \\
\\
breaksOf & \; : \; \Stmt \to \pset{\Lab} \\
breaksOf([x:=a]^\ell) & \eq \emptyset \\
breaksOf([\skip]^\ell) & \eq \emptyset \\
breaksOf([x_1,\ldots,x_:=a_1,\ldots,a_n]^\ell) & \eq \emptyset \\
breaksOf([\print a]^\ell) & \eq \emptyset \\
breaksOf([\cont]^\ell) & \eq \emptyset \\
breaksOf([\breakc]^\ell) & \eq \{\ell\} \\
breaksOf(S_1;S_2) & \eq breaksOf(S_1) \cup breaksOf(S_2) \\
breaksOf(\ifl [b]^\ell \thenl S_1 \elsel S_2) & \eq breaksOf(S_1) \cup breaksOf(S_2) \\
breaksOf(\while [b]^\ell \do S) & \eq \emptyset
\end{align*}
 
We presented above the changes made on the definition of the flow of the program.
These definitions can be used in all monotone frameworks. Regarding
the Strongly Live Variable analysis, these constructs are easy to handle. They
are just like $\skip$ as they do not change the state of the data whatsoever: according to the
semantics informally presented above (cf. the formal rules in
Table \ref{semantics}), the state was frozen with an annotation and then de-annotated (thus recovered)
when execution restarts at the right program point. Therefore, we have:
\begin{align*}
kill_{SLV}([\cont]^\ell) \eq kill_{SLV}([\breakc]^\ell) & \eq \emptyset \\
\\
gen_{SLV} ([\cont]^\ell,l) \eq gen_{SLV} ([\breakc]^\ell,l) & \eq \emptyset
\end{align*}
 
We can now analyze two example programs. First, we will do Strongly Live Variable Analysis on the following program:
 
\program{progbc}[progbc]


\restabRtiny{Strongly Live Variable Analysis on Program \ref{progbc} (with $\breakc$ and $\cont$)}{result_bc}[result_bc]

The results are in Table \ref{result_bc}.
First of all, we can notice that there are certain unacessible program points (namely those immediately
after the $\breakc$ and the $\cont$ statements, 6 and 9). Actually, there are values computed
for those points as well (which are not empty, meaning they get modified during chaotic
iteration). This happens because there is a path
from those statements to the while condition. So, as we are performing a backward analysis, information
goes from the while condition to those points. However, as these are inacessible points, there is
no way that information can go from there to any acessible part of the program and contaminate
the information there (being joined). So, the results
we compute for that points are not actually relevant to the whole program. Those values are actually
correct in the sense that if we could point to an arbitrary label and start executing there, then 
that those values would be correct for those points. A last remark about this: one could
think a forward analysis would cause problems as information would flow from those points
and be joined with the information at accessible points of the program. However,
recall that the initial values at
these inaccessible points would be bottom (or top) and
would remain so because information would never flow
to these points. Then, we would be joining with bottom (meeting with
top) at the accessible points, which amounts to nothing. In the example program, one can observe that information from that points did not contaminate the rest by realizing that $a$ is never live in accessible points although it is used in an assignment to $y$ in those inaccessible points.


We will also consider a second program, on which we will perform
Available Expression Analyses (again using our \haskell\ modules).

\newpage
\program{progbc2.tex}[progbc2]


\restabR{Available Expression Analysis on Program \ref{progbc2} (with $\breakc$ and $\cont$)}{result_bc_ae}[result_bc_ae]

The results of this analysis can be found in Table \ref{result_bc_ae}.
We can easly check that the values were correctly computed. The only non-trivial
expression in program \ref{progbc2} is $x*x$. So that is the only one that can ever appear.
Now, in the inacessible program point (9), we always have $\top$ (this is a must analysis, so
join is intersection). We can also see that the $\cont$ statement was well captured by the analysis
because expression $x*x$ is always
available at point 2 (either it comes from before the while, or before the continue). If the continue was ignored, that expression would have been destroyed at point 9. As for the $\breakc$ statement, we can see that altough expression $x*x$ would be passed to point 10 from point 2, 
as it is not available before the break, it is not necessarily available at point 10 (the break
goes directly there).

\begin{table}\label{semantics}
\caption{Modifications to the Operational Semantics}
{\small
\begin{eqnarray*}
\text{state} & \sigma = (\eta, out) \in (Var \to \Z) \times \Z^\star & \\
& & \\
& & \\
\lbrack print \rbrack\;\; &
 \pair{\print a, \sigma = (\eta,out)} \longrightarrow (\eta, snoc(out,\A{a}\eta))\; &\\
& & \\
\lbrack multass\rbrack\;\; &
 \pair{x_1,\ldots,x_n := a_1,\ldots,a_n, \sigma = (\eta,out)} \longrightarrow
 (\eta[x_1\mapsto \A{a_1}\eta]\ldots[x_n\mapsto \A{a_n}\eta] , out)\; &\\
& & \\
\lbrack cont\_fire\rbrack\;\; &
 \pair{\cont, \sigma} \longrightarrow [\sigma]^{continue} \; &\\
& & \\
\lbrack break\_fire\rbrack\;\; &
 \pair{\breakc, \sigma} \longrightarrow [\sigma]^{break} \; &\\
& & \\
\lbrack cont\_prop\rbrack\;\; &
\begin{prooftree}
\pair{S_1,\sigma} \longrightarrow [\sigma']^{continue}
\justifies
\pair{S_1 ; S_2,\sigma} \longrightarrow [\sigma']^{continue}
\thickness=0.08em
\end{prooftree}\\
& & \\
\lbrack break\_prop\rbrack\;\; &
\begin{prooftree}
\pair{S_1,\sigma} \longrightarrow [\sigma']^{break}
\justifies
\pair{S_1 ; S_2,\sigma} \longrightarrow [\sigma']^{break}
%\thickness=0.08em
\end{prooftree}\\
& & \\
\lbrack cont\_catch\rbrack\;\; &
\begin{prooftree}
\pair{S,\sigma} \longrightarrow [\sigma']^{continue}
\justifies
\pair{\while [b]^\ell \do S,\sigma} \longrightarrow \pair{\while [b]^\ell \do S,\sigma'}
\thickness=0.08em
\end{prooftree}\\
& & \\
\lbrack break\_catch\rbrack\;\; &
\begin{prooftree}
\pair{S,\sigma} \longrightarrow [\sigma']^{break}
\justifies
\pair{\while [b]^\ell \do S,\sigma} \longrightarrow \sigma
\thickness=0.08em
\end{prooftree}\\
\end{eqnarray*}
}
\end{table}
 
\end{document}
 
  
